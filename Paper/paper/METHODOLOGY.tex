\section{METHODOLOGY}
\label{sec:Meth}
\subsection{System Overview}
\label{subsection:overview}

\begin{figure}[!htq]
	\centering
	\textsc{\includegraphics[width=3.4in]{figure/pipeline.eps}}
	\caption{An overview of our layout estimation algorithm pipeline. First we adopt a multi-scale CNN achitecture to predict geometric information from RGB image, including depth and normals. Then we encode abovementioned information into FCNN , which help to accurately estimate the layout. Optimization framwork based on perspective projection restriction is adopted to generate final precise layout estimates.}
	\label{fig:pipeline}
\end{figure}

The pipeline is shown in Fig. \ref{fig:pipeline}. The coarse layout estmation about semantic layout surfaces for a single RGB image, are predicted by fully convolutional neural network with geometric information emmbeded, including depth and normal information. These geometric information are estimated from source RGB image by a multi-scale convolutional architecture\cite{eigen2015predicting}. This will be decribied in Sec. \ref{subsection:CNN}. Then based on optimization framwork proposed in \cite{dasgupta2016delay}, which mainly uses perspective projection constraints, we can obtain final precise layout estimation results.

%The pipeline is shown in Fig. \ref{fig1:pipeline}. The coarse layout estmation about semantic layout surfaces for a single RGB image, are predicted by fully convolutional neural network with geometric information emmbeded, including depth and normal information. These geometric information are estimated from source RGB image by a multi-scale convolutional architecture\cite{eigen2015predicting}. This will be decribied in Sec. \ref{subsection:CNN}. Then based on optimization framwork proposed in \cite{dasgupta2016delay}, which mainly uses perspective projection constraints, we modify score function by adding edge shape restriction. It is mainly for the sake of consistency between layout candidate generated during optimization procedure and learned layout edge map trained from network. We call this belief edge map restriction, shown in Fig. \ref{fig1:pipeline}, which we will describe in Sec. \ref{subsection:optimization} in detail.



\subsection{Geometric Based CNN for Coarse Layout Estmation}
\label{subsection:CNN}

\subsection{Geometric Information}
In previous work, \cite{dasgupta2016delay} \cite{ren2016coarse} achieved to use fully convolutional neural network(FCNN) or multi-task fully convolutional neural network(MFCNN) to predict coarse semantic layout surfaces and layout edges. However, due to much clutter, complex textures and illumination variations existed, semantic surfaces like walls are visually seperated in to pieces, making whole srufaces difficult to aggregate together. Fig. \ref{fig:fcn} shows layout estimation results using FCNN architecture for prediction. Under the comparison between the predicted results and the ground truth, we can see that due to the environmental effect of indoor scenes, layout results estimated from FCNN are not reliable. When there exits clutter right on the boundaries, such critical clues are partially or entirely excluded, and thus we can not tell location of each plane precisely. Moreover, an entire plane may be predicted separately into pieces due to clutter lay in the plane.


\begin{figure}[!htq]
	\centering
	\textsc{\includegraphics[width=3.4in]{figure/fcn.eps}}
	\caption{Layout estimation results using FCNN architecture for prediction in \cite{dasgupta2016delay} \cite{ren2016coarse}.}
	\label{fig:fcn}
\end{figure}



Meanwhile, geometric information such as normals and depth, can serve as clues tending to merge big planes together, with interference factors like clutter, textures and illumination eliminated to varying degrees. These mid-level geometric information can be used to adapt and imrove performance for layout estimation compared to using RGB only. Since we restrict the input to single RGB image for the most general case, we 






\subsection{Modified Optimization}
\label{subsection:optimization}
We adopt a popular model that several researchers\cite{hedau2009recovering}\cite{dasgupta2016delay}\cite{ren2016coarse} have been used to parameterize indoor layout based on "Manhattan World" assumption. Indoor scene layout can be modeled as 
\begin{equation}
	\label{1.Layout}
	L = (l1, l2, l3, l4, v)
\end{equation}
where $l_{i}$ stands for $i^{th}$ vanishing line and $v$ stands for the specific vanishing point. The whole scene is equivalent to be labeled to five semantic surfaces, coresponding to (front, left, right, ceiling, ground), as described in Fig. \ref{fig:2.model}. Based ob Eq. (\ref{1.Layout}), each surface can be reconstructed with vanishing lines, extension lines between vanishing point and Intersection point, and image boundaries. Due to the camera pose, not five surfaces are always visible, and such layout can still be modeled by Eq. (\ref{1.Layout}). Different examples are given in Fig. \ref{fig:3.example}.