\relax 
\citation{hedau2009recovering}
\citation{wang2013discriminative}
\citation{schwing2012efficient}
\citation{schwing2013box}
\citation{lee2009geometric}
\citation{ramalingam2013manhattan}
\@writefile{toc}{\contentsline {section}{\numberline {1} INTRODUCTION}{1}}
\newlabel{sec:intro}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of indoor scene images. (a) Input images. (b) Layout estimation with semantic labels. (c) Layout visulization superimposed on the input image.}}{1}}
\newlabel{fig:definition}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Examples of indoor scene images. (a) Much clutter. (b) Too bright. (c) Too dark. (d-f) Different views.}}{1}}
\newlabel{fig:case}{{2}{1}}
\citation{geiger2015joint}
\citation{ren2016three}
\citation{guo2015predicting}
\citation{long2015fully}
\citation{chen2016deeplab}
\citation{girshick2015fast}
\citation{ren2015faster}
\citation{gupta2015indoor}
\citation{badrinarayanan2017segnet}
\citation{mallya2015learning}
\citation{long2015fully}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{zhang2016learning}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{ren2016coarse}
\citation{dasgupta2016delay}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{dasgupta2016delay}
\citation{LeeRoomNet17}
\citation{dasgupta2016delay}
\citation{dasgupta2016delay}
\citation{lee2009geometric}
\citation{hedau2009recovering}
\citation{geiger2015joint}
\citation{geiger2015joint}
\citation{ren2016three}
\citation{long2015fully}
\citation{chen2016deeplab}
\citation{girshick2015fast}
\citation{ren2015faster}
\citation{gupta2015indoor}
\citation{badrinarayanan2017segnet}
\citation{mallya2015learning}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{zhang2016learning}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{eigen2015predicting}
\citation{dasgupta2016delay}
\citation{eigen2015predicting}
\@writefile{toc}{\contentsline {section}{\numberline {2} RELATEDWORK}{3}}
\newlabel{sec:Rel}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3} Our Method}{3}}
\newlabel{sec:Meth}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1} System Overview}{3}}
\newlabel{subsection:overview}{{3.1}{3}}
\citation{ren2016three}
\citation{ren2016three}
\citation{dasgupta2016delay}
\citation{eigen2015predicting}
\citation{eigen2015predicting}
\citation{eigen2015predicting}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{ren2016coarse}
\citation{ren2016coarse}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An overview of our layout estimation algorithm pipeline. First we adopt a multi-scale CNN achitecture to predict geometric information from RGB image, including depth and normals. Then we encode abovementioned information into FCNN , which help to accurately estimate the layout. Optimization framwork based on perspective projection restriction is adopted to generate final precise layout estimates.}}{4}}
\newlabel{fig:pipeline}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Estimation of depth and normal from a single RGB image using the multi-task FCN in \cite  {eigen2015predicting}.}}{4}}
\newlabel{fig:depthandnormal}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2} Geometric Fusion FCNN for Coarse Layout Estimation}{4}}
\newlabel{sec:depth_normal}{{3.2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3} Surface Label Prediction using MFCN}{4}}
\newlabel{sec:surfacelabel}{{3.3}{4}}
\citation{ren2016coarse}
\citation{ren2016coarse}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The network architecture of \cite  {ren2016coarse}, illustration of the FCN-VGG16 with two output branches. We only use the second branch to learn semantic surface and prune the first branch. By the way, the number of convolution layers in this figure may be wrong, i check the prototxt of VGG16 and FCN-32s, there should be three layers in the part which are pointed by black arrow. }}{5}}
\newlabel{fig:coarsetofine}{{3.3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A simple network architecture taking the RGB, depth and normal together as input to a VGG16 FCN. \leavevmode {\color  [rgb]{1.00,0.00,0.00}(cxj: add more details of each layer.)}}}{5}}
\newlabel{fig:fcn-multi-channel}{{6}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A network architecture that fuses the RGB, depth and normal together later. \leavevmode {\color  [rgb]{1.00,0.00,0.00}(cxj: add more details of each layer.)}}}{5}}
\newlabel{fig:fcn-geometric-fusion}{{7}{5}}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{hedau2009recovering}
\citation{dasgupta2016delay}
\citation{ren2016coarse}
\citation{ren2016three}
\citation{dasgupta2016delay}
\citation{hedau2009recovering}
\citation{mallya2015learning}
\citation{dasgupta2016delay}
\citation{ren2016three}
\bibstyle{IEEEbib}
\bibdata{refs}
\bibcite{hedau2009recovering}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Layout estimation results using different architectures. Row from top to bottom: (a) the input RGB image. (b)(c)(d)Surface predictions using the FCNN architecture used in \cite  {dasgupta2016delay,ren2016coarse}, our FCN-MC and FCN-GF respectively. (e) The ground truth. }}{6}}
\newlabel{fig:fcn-comparison}{{8}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Pixelwise accuracy for surface label prediction.}}{6}}
\newlabel{table:fcn-accuracy}{{1}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Performance benchmarking on Hedau's dataset}}{6}}
\newlabel{table:comparison-hedau}{{2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4} Layout Generation}{6}}
\newlabel{subsection:optimization}{{3.4}{6}}
\newlabel{eq:Layout}{{1}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4} RESULTS}{6}}
\newlabel{sec:Res}{{4}{6}}
\bibcite{wang2013discriminative}{2}
\bibcite{schwing2012efficient}{3}
\bibcite{schwing2013box}{4}
\bibcite{lee2009geometric}{5}
\bibcite{ramalingam2013manhattan}{6}
\bibcite{geiger2015joint}{7}
\bibcite{ren2016three}{8}
\bibcite{guo2015predicting}{9}
\bibcite{long2015fully}{10}
\bibcite{chen2016deeplab}{11}
\bibcite{girshick2015fast}{12}
\bibcite{ren2015faster}{13}
\bibcite{gupta2015indoor}{14}
\bibcite{badrinarayanan2017segnet}{15}
\bibcite{mallya2015learning}{16}
\bibcite{dasgupta2016delay}{17}
\bibcite{ren2016coarse}{18}
\bibcite{zhang2016learning}{19}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance benchmarking on the LSUN dataset}}{7}}
\newlabel{table:comparison-lsun}{{3}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {5} CONCLUSION}{7}}
\newlabel{sec:Con}{{5}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6} REFERENCES}{7}}
\newlabel{sec:ref}{{6}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {7} References}{7}}
\bibcite{LeeRoomNet17}{20}
\bibcite{eigen2015predicting}{21}
